# Hawkeye VLM Requirements
# For Vision-Language Models (Qwen-VL, LLaVA, etc.)
# Install: pip install -r requirements-vlm.txt
# Requires: CUDA GPU with 24GB+ VRAM (or use quantization)

# Include DL requirements
-r requirements-dl.txt

# HuggingFace Ecosystem
transformers>=4.36.0
datasets>=2.15.0
huggingface_hub>=0.19.0

# Quantization (for running large models on limited GPU)
bitsandbytes>=0.41.0   # 4-bit/8-bit quantization
peft>=0.6.0            # Parameter-efficient fine-tuning

# VLM Specific
qwen-vl-utils>=0.0.2   # Qwen-VL utilities (if using Qwen)

# Video Processing for VLM
decord>=0.6.0          # Fast video decoding
av>=10.0.0             # PyAV for video

# API Clients (for cloud VLM APIs)
openai>=1.3.0          # GPT-4V
anthropic>=0.7.0       # Claude 3

# Optional: Local inference optimization
# vllm>=0.2.0          # Fast inference (Linux only)
# flash-attn>=2.3.0    # Flash Attention (requires specific CUDA)

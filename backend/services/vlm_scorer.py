"""
VLM (Vision Language Model) Scoring Service
Uses GPT-4V to analyze video frames and provide UPDRS scores
"""

import os
import cv2
import base64
import json
from typing import Dict, Any, Optional, List, Tuple
from openai import OpenAI


class VLMScorer:
    """GPT-4V based video analysis for Parkinson's Disease assessment"""

    def __init__(self):
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            print("Warning: OPENAI_API_KEY not found. VLM scoring will not work.")
            self.client = None
        else:
            self.client = OpenAI(api_key=api_key)

    def is_available(self) -> bool:
        """Check if VLM service is available"""
        return self.client is not None

    def _get_prompt(self, task_type: str) -> str:
        """Generate task-specific prompt for GPT-4V"""
        criteria = {
            "finger_tapping": "ì†ê°€ë½ íƒœí•‘ì˜ ì†ë„, ì§„í­, ë§ì„¤ì„, ë©ˆì¶¤, ì§„í­ ê°ì†Œë¥¼ í‰ê°€í•˜ì„¸ìš”.",
            "hand_movement": "ì† ì—´ê³  ë‹«ê¸°ì˜ ì†ë„, ì§„í­, ë§ì„¤ì„, ë©ˆì¶¤, ì§„í­ ê°ì†Œë¥¼ í‰ê°€í•˜ì„¸ìš”.",
            "leg_agility": "ë°œ êµ¬ë¥´ê¸°ì˜ ì†ë„, ì§„í­, ë§ì„¤ì„, ë©ˆì¶¤, ì§„í­ ê°ì†Œë¥¼ í‰ê°€í•˜ì„¸ìš”.",
            "gait": "ê±¸ìŒê±¸ì´ì˜ ë³´í­, ì†ë„, ë°œ ë“¤ì–´ì˜¬ë¦¼ ë†’ì´, ë’¤ê¿ˆì¹˜ ì°©ì§€, íšŒì „, íŒ” í”ë“¤ë¦¼ì„ í‰ê°€í•˜ì„¸ìš”."
        }

        task_criteria = criteria.get(task_type, "ì›€ì§ì„ì˜ ì§ˆê³¼ íŒŒí‚¨ìŠ¨ë³‘ ì§•í›„ë¥¼ í‰ê°€í•˜ì„¸ìš”.")
        task_name_kr = {
            "finger_tapping": "ì†ê°€ë½ íƒœí•‘",
            "hand_movement": "ì† ì›€ì§ì„",
            "leg_agility": "ë‹¤ë¦¬ ë¯¼ì²©ì„±",
            "gait": "ë³´í–‰"
        }.get(task_type, task_type)

        prompt = f"""ë‹¹ì‹ ì€ íŒŒí‚¨ìŠ¨ë³‘ ì „ë¬¸ ì‹ ê²½ê³¼ ì˜ì‚¬ì…ë‹ˆë‹¤.
í™˜ìê°€ '{task_name_kr}' ê²€ì‚¬ë¥¼ ìˆ˜í–‰í•˜ëŠ” ì˜ìƒ í”„ë ˆì„ë“¤ì„ ë¶„ì„í•˜ì„¸ìš”.
{task_criteria}

MDS-UPDRS ì²™ë„ë¡œ ìš´ë™ ì¥ì•  ì‹¬ê°ë„ë¥¼ í‰ê°€í•˜ì„¸ìš”:
0: ì •ìƒ (ë¬¸ì œ ì—†ìŒ)
1: ê²½ë¯¸ (ì•½ê°„ì˜ ëŠë¦¼/ì‘ì€ ì§„í­, ê°ì†Œ ì—†ìŒ)
2: ê°€ë²¼ì›€ (ê°€ë²¼ìš´ ëŠë¦¼/ì§„í­, ì•½ê°„ì˜ ê°ì†Œë‚˜ ë§ì„¤ì„)
3: ì¤‘ë“±ë„ (ì¤‘ë“±ë„ì˜ ëŠë¦¼/ì§„í­, ë¹ˆë²ˆí•œ ë§ì„¤ì„/ë©ˆì¶¤)
4: ì‹¬ê° (ì‹¬í•œ ì¥ì• , ê±°ì˜ ìˆ˜í–‰ ë¶ˆê°€)

ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•˜ì„¸ìš”:
{{
  "score": <0-4 ì •ìˆ˜>,
  "confidence": <0.0-1.0 í™•ì‹ ë„>,
  "findings": [
    "<ê´€ì°°ëœ íŠ¹ì§• 1>",
    "<ê´€ì°°ëœ íŠ¹ì§• 2>",
    "<ê´€ì°°ëœ íŠ¹ì§• 3>"
  ],
  "reasoning": "<ì ìˆ˜ ë¶€ì—¬ ê·¼ê±° ì„¤ëª…>"
}}
"""
        return prompt

    def _extract_frames(self, video_path: str, max_frames: int = 12) -> List[Any]:
        """Extract evenly spaced frames from video"""
        cap = cv2.VideoCapture(video_path)

        if not cap.isOpened():
            raise ValueError(f"Cannot open video: {video_path}")

        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

        # Calculate frame indices to sample
        if total_frames <= max_frames:
            frame_indices = list(range(total_frames))
        else:
            frame_indices = [int(i * total_frames / max_frames) for i in range(max_frames)]

        frames = []
        for idx in frame_indices:
            cap.set(cv2.CAP_PROP_POS_FRAMES, idx)
            ret, frame = cap.read()
            if ret:
                # Resize to reduce token usage (512x512)
                frame = cv2.resize(frame, (512, 512))
                frames.append(frame)

        cap.release()
        return frames

    def _encode_frame(self, frame) -> str:
        """Encode OpenCV frame to base64"""
        _, buffer = cv2.imencode('.jpg', frame, [cv2.IMWRITE_JPEG_QUALITY, 85])
        return base64.b64encode(buffer).decode('utf-8')

    def analyze_video(
        self,
        video_path: str,
        task_type: str,
        max_frames: int = 12
    ) -> Dict[str, Any]:
        """
        Analyze video using GPT-4V and return UPDRS score with reasoning.

        Args:
            video_path: Path to the video file
            task_type: Type of motor task (finger_tapping, gait, etc.)
            max_frames: Maximum number of frames to send to API

        Returns:
            Dict with score, confidence, findings, reasoning
        """
        if not self.client:
            return {
                "success": False,
                "error": "VLM ì„œë¹„ìŠ¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. (API Key Missing)"
            }

        if not os.path.exists(video_path):
            return {
                "success": False,
                "error": f"ì˜ìƒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {video_path}"
            }

        try:
            # Extract frames
            frames = self._extract_frames(video_path, max_frames)

            if not frames:
                return {
                    "success": False,
                    "error": "ì˜ìƒì—ì„œ í”„ë ˆì„ì„ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                }

            # Build message content
            prompt = self._get_prompt(task_type)
            content = [{"type": "text", "text": prompt}]

            # Add frames as images
            for frame in frames:
                base64_image = self._encode_frame(frame)
                content.append({
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:image/jpeg;base64,{base64_image}",
                        "detail": "low"  # Use low detail to reduce tokens
                    }
                })

            # Call GPT-4V API
            response = self.client.chat.completions.create(
                model="gpt-4o",  # or "gpt-4-vision-preview"
                messages=[{"role": "user", "content": content}],
                max_tokens=500,
                temperature=0.3
            )

            output_text = response.choices[0].message.content

            # Parse JSON response
            try:
                start = output_text.find('{')
                end = output_text.rfind('}') + 1
                json_str = output_text[start:end]
                data = json.loads(json_str)

                return {
                    "success": True,
                    "score": data.get("score", -1),
                    "confidence": data.get("confidence", 0.0),
                    "findings": data.get("findings", []),
                    "reasoning": data.get("reasoning", ""),
                    "raw_output": output_text,
                    "frames_analyzed": len(frames)
                }
            except json.JSONDecodeError:
                return {
                    "success": True,
                    "score": -1,
                    "confidence": 0.0,
                    "findings": [],
                    "reasoning": output_text,
                    "raw_output": output_text,
                    "frames_analyzed": len(frames),
                    "parse_error": True
                }

        except Exception as e:
            return {
                "success": False,
                "error": f"VLM ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            }

    def format_result_for_chat(self, result: Dict[str, Any], ml_score: Optional[int] = None) -> str:
        """Format VLM result for chat display"""
        if not result.get("success"):
            return f"âŒ VLM ë¶„ì„ ì‹¤íŒ¨: {result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}"

        score = result.get("score", -1)
        confidence = result.get("confidence", 0.0)
        findings = result.get("findings", [])
        reasoning = result.get("reasoning", "")

        severity_map = {
            0: "ì •ìƒ (Normal)",
            1: "ê²½ë¯¸ (Slight)",
            2: "ê°€ë²¼ì›€ (Mild)",
            3: "ì¤‘ë“±ë„ (Moderate)",
            4: "ì‹¬ê° (Severe)"
        }
        severity = severity_map.get(score, "ì•Œ ìˆ˜ ì—†ìŒ")

        response = f"""ğŸ”¬ **VLM ì •ë°€ ë¶„ì„ ê²°ê³¼** (GPT-4V)

ğŸ“Š **UPDRS ì ìˆ˜: {score}ì ** ({severity})
ğŸ¯ í™•ì‹ ë„: {confidence*100:.0f}%

**ì£¼ìš” ê´€ì°° ì†Œê²¬:**
"""
        for i, finding in enumerate(findings, 1):
            response += f"  {i}. {finding}\n"

        response += f"\n**ë¶„ì„ ê·¼ê±°:**\n{reasoning}"

        # Compare with ML score if available
        if ml_score is not None:
            diff = abs(score - ml_score)
            if diff == 0:
                response += f"\n\nâœ… ML ëª¨ë¸ ê²°ê³¼({ml_score}ì )ì™€ **ì¼ì¹˜**í•©ë‹ˆë‹¤."
            elif diff == 1:
                response += f"\n\nâš ï¸ ML ëª¨ë¸ ê²°ê³¼({ml_score}ì )ì™€ **1ì  ì°¨ì´**ê°€ ìˆìŠµë‹ˆë‹¤."
            else:
                response += f"\n\nğŸ”´ ML ëª¨ë¸ ê²°ê³¼({ml_score}ì )ì™€ **{diff}ì  ì°¨ì´**ê°€ ìˆìŠµë‹ˆë‹¤. ì „ë¬¸ì˜ í™•ì¸ì„ ê¶Œì¥í•©ë‹ˆë‹¤."

        return response

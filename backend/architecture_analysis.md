# Hawkeye PD: Multi-Agent Architecture & Feature Analysis

## 1. Multi-Agent Structure Analysis

### Current Status
The current system follows a linear pipeline:
`Orchestrator` -> `VisionAgent` (Extraction) -> `ClinicalAgent` (Metrics) -> `ReportAgent` (Text).

### Proposed Evolution: "Collaborative Diagnostic Agents"
To handle the complexity of Parkinson's Disease (PD) assessment, we should move from a linear pipeline to a **Collaborative System**.

- **Orchestrator (Supervisor)**: Manages the workflow but also handles "Disagreement". If the Vision Agent detects low confidence, the Orchestrator might request a different analysis mode or flag for human review.
- **Vision Agent (The "Eye")**:
    - **Role**: Extracts raw data.
    - **Sub-Agents**:
        - `SkeletonExtractor`: MediaPipe (Deterministic, fast).
        - `TextureAnalyzer`: RGB/Optical Flow (For subtle tremors not moving joints).
        - `SceneUnderstander`: VLM (Context, environment checks).
- **Clinical Agent (The "Calculator")**:
    - **Role**: Computes UPDRS-relevant metrics (frequency, amplitude, decrement).
    - **Input**: Skeleton data.
- **Interpretation Agent (The "Doctor" - VLM)**:
    - **Role**: Synthesizes data.
    - **Input**: Metrics + Visual Summaries (Heatmaps) + Patient History.
    - **Output**: Natural language report and final score confidence.

## 2. Visual Features Analysis: When & Why?

For PD assessment, visual aids serve two purposes: **Calculation** (internal) and **Explanation** (external/UI).

| Feature | What it is | Clinical Relevance (PD) | Necessity |
| :--- | :--- | :--- | :--- |
| **Skeleton Overlay** | Lines connecting joints | Verifying if the model tracked the correct body part. Essential for debugging "bad data". | **CRITICAL** |
| **Motion Heatmap** | Intensity of pixel changes | **Bradykinesia/Freezing**: Shows if movement is large (red) or barely there (blue). <br> **Tremor**: Shows localized high-intensity spots. | **HIGH** |
| **Trajectory Map** | Lines tracing path of hand/foot | **Dyskinesia/Coordination**: Shows if movement is smooth (straight lines) or jerky/irregular (scribbles). | **HIGH** |
| **Attention Map** | Where the AI "looked" | **Explainability**: If using a VLM/Deep Model, proves the model looked at the hand, not the background. | **MEDIUM** (High if using VLM) |

### Recommendation
- **Always generate**: Skeleton & Motion Heatmap.
- **On Demand**: Trajectory Map (specifically for Finger Tapping/Hand Movement tasks).
- **Advanced**: Attention Map (only if we integrate a VLM that supports it, to build trust).

## 3. Model Selection: VLM vs RGB vs Skeleton

We do not need to choose *one*; we need the right tool for the right layer.

### A. Skeleton / Kinematic Features (The Foundation)
- **Why**: UPDRS is defined by specific physical events (e.g., "amplitude decrement", "hesitation"). Geometry is the best way to measure this.
- **Pros**: Fast, privacy-friendly, mathematically explainable.
- **Cons**: Fails on occlusion, misses "texture" (sweating, facial masking).
- **Role**: **Primary Metric Generator**.

### B. RGB / Video Models (The Texture)
- **Why**: Some symptoms are visual but not skeletal (e.g., *facial masking* (hypomimia), subtle *resting tremor*).
- **Role**: **Secondary Feature Extractor** for specific tasks where skeleton fails.

### C. VLM (Vision-Language Model) (The Brain)
- **Why**: "Reasoning". A skeleton model can calculate "3Hz frequency", but a VLM can say "The patient appears anxious and has difficulty starting the movement (hesitation)."
- **Role**: **High-Level Synthesis**. It reads the *Charts* generated by A & B and writes the report.

## 4. Strategic Roadmap

1.  **Phase 1 (Current)**: Solidify **Skeleton Analysis**. Ensure `metrics_calculator.py` produces accurate frequency/amplitude graphs.
2.  **Phase 2 (Visuals)**: Implement **Motion Heatmaps** and **Trajectory Maps** in the UI. These allow the doctor to "see" the metrics.
3.  **Phase 3 (VLM Integration)**: Use a VLM (GPT-4o/Gemini) to **read the metrics and heatmaps**.
    - *Input*: "Here is a graph showing decreasing amplitude. Here is a heatmap showing movement focused on the wrist."
    - *Task*: "Write a clinical summary."
    - *Benefit*: This is cheaper and more accurate than sending the raw video to the VLM, and avoids privacy issues of sending raw video to cloud (if using local metrics).

## Conclusion
- **Multi-Agent**: Split "Metric Calculation" (Math) from "Interpretation" (VLM).
- **Features**: Prioritize **Trajectory Maps** for motor tasks.
- **Models**: **Hybrid**. Skeleton for math, VLM for words.

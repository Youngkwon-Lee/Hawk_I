"""
Video Analysis Route
ROI Detection + Task Classification
"""

from flask import Blueprint, request, jsonify, current_app
import os
import cv2
from werkzeug.utils import secure_filename
import sys
import threading
import json
import time

# Add services directory to path
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from services.roi_detector import MovementBasedROI, ROIResult
from services.task_classifier import TaskClassifier, TaskClassificationResult
from services.mediapipe_processor import MediaPipeProcessor
from services.metrics_calculator import MetricsCalculator
from services.updrs_scorer import UPDRSScorer
from services.interpretation_agent import InterpretationAgent
from services.progress_tracker import init_analysis, update_step, complete_analysis, fail_analysis
from agents.orchestrator import OrchestratorAgent
from domain.context import AnalysisContext
from dataclasses import asdict

bp = Blueprint('analyze', __name__, url_prefix='/api')


def allowed_file(filename):
    """Check if file extension is allowed"""
    ALLOWED_EXTENSIONS = {'mp4', 'avi', 'mov', 'webm', 'mkv'}
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS


def process_video_background(video_path, video_id, patient_id, manual_test_type, app_config):
    """
    Background task for video analysis using Multi-Agent Orchestrator
    """
    try:
        print(f"\n{'='*50}")
        print(f"Processing video: {os.path.basename(video_path)} (ID: {video_id})")
        print(f"{'='*50}\n")

        # Initialize Orchestrator
        orchestrator = OrchestratorAgent()
        
        # Define progress callback
        def progress_callback(step_name, status, **kwargs):
            update_step(video_id, step_name, status, **kwargs)

        # Create Context
        ctx = AnalysisContext(video_path=video_path, video_id=video_id)
        
        # Run Analysis
        ctx = orchestrator.process(ctx, on_progress_update=progress_callback)
        
        if ctx.error:
            raise Exception(ctx.error)

        # Post-processing for Visualizations & Response Formatting
        print("\nStep 4: Generating visualizations...")
        
        # Extract data from context
        landmarks = ctx.skeleton_data.get("landmarks", [])
        metrics = ctx.kinematic_metrics
        updrs_result = ctx.clinical_scores # This is UPDRSScore object
        ai_result = ctx.report # This is Report object
        
        # Convert landmarks to dict for visualization
        # Note: landmarks are already dicts (converted by VisionAgent using asdict)
        frames_data = []
        for lf in landmarks:
            frames_data.append({
                "frame": lf.get("frame_number", 0),
                "timestamp": lf.get("timestamp", 0.0),
                "keypoints": lf.get("landmarks", [])
            })
            
        # Generate Visualizations
        from services.visualization import VisualizationService
        viz_service = VisualizationService()
        
        # Heatmap
        update_step(video_id, "heatmap", "in_progress")
        heatmap_path = os.path.join(app_config['UPLOAD_FOLDER'], f"{video_id}_heatmap.png")
        viz_service.generate_heatmap(frames_data, heatmap_path, video_path=video_path)
        update_step(video_id, "heatmap", "completed")
        
        # Temporal Map
        update_step(video_id, "temporal_map", "in_progress")
        temporal_path = os.path.join(app_config['UPLOAD_FOLDER'], f"{video_id}_temporal.png")
        mode = "pose" if ctx.task_type in ["gait", "leg_agility"] else "hand"
        viz_service.generate_temporal_map(frames_data, temporal_path, mode=mode, video_path=video_path)
        update_step(video_id, "temporal_map", "completed")
        
        # Attention Map
        update_step(video_id, "attention_map", "in_progress")
        attention_path = os.path.join(app_config['UPLOAD_FOLDER'], f"{video_id}_attention.png")
        viz_service.generate_attention_map(frames_data, attention_path)
        update_step(video_id, "attention_map", "completed")

        # Overlay Video - Use skeleton video generated by VisionAgent
        skeleton_video_path = ctx.vision_meta.get("skeleton_video_path")
        if skeleton_video_path and os.path.exists(skeleton_video_path):
            skeleton_video_url = f"/files/{os.path.basename(skeleton_video_path)}"
        else:
            # Fallback to original video if skeleton not available
            skeleton_video_url = f"/files/{os.path.basename(video_path)}"
        update_step(video_id, "overlay_video", "completed", result_url=skeleton_video_url)

        # Prepare Response
        
        # Convert objects to dicts
        updrs_dict = updrs_result if updrs_result else None
        
        ai_interpretation = None
        if ai_result:
            ai_interpretation = {
                "summary": ai_result.summary_for_patient,
                "explanation": ai_result.summary_for_clinician,
                "recommendations": ai_result.recommendations
            }

        # Reasoning Log conversion
        reasoning_log = [step.model_dump(mode='json') for step in ctx.reasoning_log]

        response = {
            "success": True,
            "id": video_id,
            "patient_id": patient_id,
            "video_type": ctx.task_type,
            "auto_detected": manual_test_type is None,
            "confidence": ctx.vision_meta.get("confidence", 0.0),
            "roi": {
                "x": ctx.vision_meta.get("roi", (0,0,0,0))[0],
                "y": ctx.vision_meta.get("roi", (0,0,0,0))[1],
                "w": ctx.vision_meta.get("roi", (0,0,0,0))[2],
                "h": ctx.vision_meta.get("roi", (0,0,0,0))[3]
            },
            "motion_analysis": {
                "motion_pattern": ctx.vision_meta.get("motion_pattern"),
                "motion_area_ratio": ctx.vision_meta.get("motion_area_ratio"),
                "body_part": ctx.vision_meta.get("body_part")
            },
            "reasoning": ctx.vision_meta.get("reasoning", ""), # Legacy single string
            "reasoning_log": reasoning_log, # NEW: Full log
            "video_metadata": {
                "width": 0, # TODO: Get from meta
                "height": 0,
                "fps": ctx.vision_meta.get("fps", 0),
                "duration": 0,
                "total_frames": ctx.vision_meta.get("frame_count", 0)
            },
            "metrics": metrics,
            "skeleton_data": {
                "total_frames": len(landmarks),
                "detection_rate": 0, # Calculate if needed
                "mode": mode,
                "skeleton_video_url": skeleton_video_url
            },
            "updrs_score": updrs_dict,
            "ai_interpretation": ai_interpretation,
            "events": [], # Event detector not in agents yet
            "visualization_urls": {
                "heatmap": f"/files/{video_id}_heatmap.png",
                "temporal_map": f"/files/{video_id}_temporal.png",
                "attention_map": f"/files/{video_id}_attention.png"
            }
        }

        # Save result
        result_path = os.path.join(app_config['UPLOAD_FOLDER'], f"{video_id}_result.json")
        with open(result_path, 'w', encoding='utf-8') as f:
            json.dump(response, f, ensure_ascii=False, indent=2)

        # Mark analysis as completed
        update_step(video_id, "updrs_calculation", "completed")
        update_step(video_id, "ai_interpretation", "completed")
        complete_analysis(video_id)

        print(f"\n{'='*50}")
        print(f"Analysis Complete! (ID: {video_id})")

    except Exception as e:
        print(f"\nError during analysis:")
        print(f"  {str(e)}\n")
        import traceback
        with open('error.log', 'w') as f:
            f.write(f"Error: {str(e)}\n")
            traceback.print_exc(file=f)
        traceback.print_exc()
        fail_analysis(video_id, str(e))


@bp.route('/analyze', methods=['POST'])
def start_analysis():
    """
    Start asynchronous video analysis
    """
    try:
        # Check if video file is present
        if 'video_file' not in request.files:
            return jsonify({
                "success": False,
                "error": "No video file provided"
            }), 400

        video_file = request.files['video_file']

        if video_file.filename == '':
            return jsonify({
                "success": False,
                "error": "No file selected"
            }), 400

        if not allowed_file(video_file.filename):
            return jsonify({
                "success": False,
                "error": "Invalid file type. Allowed: mp4, avi, mov, webm, mkv"
            }), 400

        # Generate unique video_id for progress tracking
        import time
        filename = secure_filename(video_file.filename)
        video_id = f"{os.path.splitext(filename)[0]}_{int(time.time())}"
        
        # Save video file
        # Note: We need to save it here before starting the thread
        video_path = os.path.join(current_app.config['UPLOAD_FOLDER'], f"{video_id}_{filename}")
        video_file.save(video_path)

        # Initialize progress tracking
        init_analysis(video_id, task_type="auto_detect")

        # Get optional parameters
        patient_id = request.form.get('patient_id', 'unknown')
        manual_test_type = request.form.get('test_type', None)
        
        # Start background thread
        thread = threading.Thread(
            target=process_video_background,
            args=(
                video_path, 
                video_id, 
                patient_id, 
                manual_test_type, 
                current_app.config.copy() # Pass config copy to thread
            )
        )
        thread.daemon = True
        thread.start()

        return jsonify({
            "success": True,
            "message": "Analysis started",
            "id": video_id,
            "status": "in_progress"
        }), 202

    except Exception as e:
        print(f"Error starting analysis: {e}")
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500


@bp.route('/analysis/result/<video_id>', methods=['GET'])
def get_analysis_result(video_id):
    """
    Get the final result of an analysis
    """
    result_path = os.path.join(current_app.config['UPLOAD_FOLDER'], f"{video_id}_result.json")
    
    if not os.path.exists(result_path):
        return jsonify({
            "success": False,
            "error": "Result not found or analysis not complete"
        }), 404
        
    try:
        with open(result_path, 'r', encoding='utf-8') as f:
            result = json.load(f)
        return jsonify(result)
    except Exception as e:
        return jsonify({
            "success": False,
            "error": f"Error reading result: {str(e)}"
        }), 500


@bp.route('/analyze-status/<analysis_id>', methods=['GET'])
def get_analysis_status(analysis_id):
    """
    Get analysis status (for async processing - future implementation)
    """
    # This is now redundant with progress_tracker but kept for compatibility
    return jsonify({
        "success": False,
        "error": "Use /api/analysis/progress/<video_id> instead"
    }), 301

